env:
  time_scaling: 5.0
  noisy: false

policy:
  delay_ms: 0   # System 1 default (fast)

training:
  learning_rate: 0.0003   # lowered from 0.001 â€” PPO needs smaller LR
  num_steps: 500000
  entropy_coef: 0.01
  gamma: 0.99
  steps_per_episode: 20
  curriculum_window: 200
  curriculum_threshold: 0.3
  # PPO
  ppo_epochs: 4
  ppo_clip: 0.2
  gae_lambda: 0.95
  batch_episodes: 20
  value_loss_coef: 0.5
